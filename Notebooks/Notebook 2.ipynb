{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2c297b6",
   "metadata": {
    "papermill": {
     "duration": 0.014541,
     "end_time": "2022-05-01T14:47:35.239312",
     "exception": false,
     "start_time": "2022-05-01T14:47:35.224771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Music genre classifier with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a956fd",
   "metadata": {
    "papermill": {
     "duration": 0.013276,
     "end_time": "2022-05-01T14:47:35.265671",
     "exception": false,
     "start_time": "2022-05-01T14:47:35.252395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To classify audio samples, we will preprocess them by calculating their MFCC, which is a temporal representation of the energy for each perceived frequency band. In this case, we are choosing 13 bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c249336",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T14:47:35.294646Z",
     "iopub.status.busy": "2022-05-01T14:47:35.294179Z",
     "iopub.status.idle": "2022-05-01T14:47:42.367060Z",
     "shell.execute_reply": "2022-05-01T14:47:42.365892Z"
    },
    "papermill": {
     "duration": 7.090374,
     "end_time": "2022-05-01T14:47:42.369764",
     "exception": false,
     "start_time": "2022-05-01T14:47:35.279390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948321ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T14:47:42.399336Z",
     "iopub.status.busy": "2022-05-01T14:47:42.398551Z",
     "iopub.status.idle": "2022-05-01T14:47:42.404673Z",
     "shell.execute_reply": "2022-05-01T14:47:42.403685Z"
    },
    "papermill": {
     "duration": 0.02316,
     "end_time": "2022-05-01T14:47:42.406813",
     "exception": false,
     "start_time": "2022-05-01T14:47:42.383653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SOURCE_PATH = '../Data/genres_original/'\n",
    "\n",
    "# Path to labels and processed data file, json format.\n",
    "JSON_PATH = 'self/data.json'\n",
    "\n",
    "# Sampling rate.\n",
    "sr = 22050\n",
    "\n",
    "# Let's make sure all files have the same amount of samples and pick a duration right under 30 seconds.\n",
    "TOTAL_SAMPLES = 29 * sr\n",
    "\n",
    "'''\n",
    "    The dataset contains 999 files.\n",
    "    But I want more so we will slice the dataset, so we get more data entries.\n",
    "    which should give me a better result? hummmm... Hopefully ... i think so ... maybe ..\n",
    "    X amount of slices => X times more training examples.\n",
    "'''\n",
    "NUM_SLICES = 10\n",
    "SAMPLES_PER_SLICE = int(TOTAL_SAMPLES / NUM_SLICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1db692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T14:47:42.434251Z",
     "iopub.status.busy": "2022-05-01T14:47:42.434030Z",
     "iopub.status.idle": "2022-05-01T14:47:42.443058Z",
     "shell.execute_reply": "2022-05-01T14:47:42.442047Z"
    },
    "papermill": {
     "duration": 0.025476,
     "end_time": "2022-05-01T14:47:42.445284",
     "exception": false,
     "start_time": "2022-05-01T14:47:42.419808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(source_path, json_path):\n",
    "\n",
    "    # create a dictionary of labels and processed data.\n",
    "    mydict = {\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "        }\n",
    "\n",
    "    # browse each file, slice it and generate the 13 band mfcc for each slice.\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(source_path)):\n",
    "        for file in filenames:\n",
    "            # exclude a corrupted wav file that makes everything crash.\n",
    "            if os.path.join(dirpath, file) != '../Data/genres_original/jazz\\\\jazz.00054.wav' or file != 'jazz.00054.wav':\n",
    "                song, sr = librosa.load(os.path.join(dirpath, file), duration=29)\n",
    "                \n",
    "                # re-sample the song to 22050 Hz. its not mandatory but it's better for the model in general.\n",
    "                for s in range(NUM_SLICES):\n",
    "                    start_sample = SAMPLES_PER_SLICE * s\n",
    "                    end_sample = start_sample + SAMPLES_PER_SLICE\n",
    "                    mfcc = librosa.feature.mfcc(y=song[start_sample:end_sample], sr=sr, n_mfcc=13)\n",
    "                    mfcc = mfcc.T\n",
    "                    mydict[\"labels\"].append(i-1)\n",
    "                    mydict[\"mfcc\"].append(mfcc.tolist())\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    # write the dictionary in the json file.    \n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(mydict, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d39b155",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T14:47:42.474345Z",
     "iopub.status.busy": "2022-05-01T14:47:42.474120Z",
     "iopub.status.idle": "2022-05-01T14:47:42.479935Z",
     "shell.execute_reply": "2022-05-01T14:47:42.478900Z"
    },
    "papermill": {
     "duration": 0.021665,
     "end_time": "2022-05-01T14:47:42.482045",
     "exception": false,
     "start_time": "2022-05-01T14:47:42.460380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(json_path):\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    # load our data into numpy arrays for TensorFlow compatibility.\n",
    "    # not going to lie did try using other arrays but it crashed and had to figure out why.\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    Y = np.array(data[\"labels\"])\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c11c68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T14:47:42.510344Z",
     "iopub.status.busy": "2022-05-01T14:47:42.509580Z",
     "iopub.status.idle": "2022-05-01T14:47:42.516271Z",
     "shell.execute_reply": "2022-05-01T14:47:42.515252Z"
    },
    "papermill": {
     "duration": 0.023308,
     "end_time": "2022-05-01T14:47:42.518482",
     "exception": false,
     "start_time": "2022-05-01T14:47:42.495174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_datasets(inputs, targets, split_size):\n",
    "    # Creating a validation set and a test set.\n",
    "    inputs_train, inputs_val, targets_train, targets_val = train_test_split(inputs, targets, test_size=split_size)\n",
    "    inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs_train, targets_train, test_size=split_size)\n",
    "    \n",
    "    # Our CNN model expects 3D input shape.\n",
    "    inputs_train = inputs_train[..., np.newaxis]\n",
    "    inputs_val = inputs_val[..., np.newaxis]\n",
    "    inputs_test = inputs_test[..., np.newaxis]\n",
    "    \n",
    "    return inputs_train, inputs_val, inputs_test, targets_train, targets_val, targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ebbebc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T14:47:42.546469Z",
     "iopub.status.busy": "2022-05-01T14:47:42.546235Z",
     "iopub.status.idle": "2022-05-01T14:47:42.555800Z",
     "shell.execute_reply": "2022-05-01T14:47:42.554875Z"
    },
    "papermill": {
     "duration": 0.025844,
     "end_time": "2022-05-01T14:47:42.558025",
     "exception": false,
     "start_time": "2022-05-01T14:47:42.532181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Still don't know how to use the tensorflow abi in general.\n",
    "'''\n",
    "\n",
    "def design_model(input_shape):\n",
    "\n",
    "    # Let's design the model architecture.\n",
    "    model = tf.keras.models.Sequential([\n",
    "        \n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(32, (2,2), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'), \n",
    "        tf.keras.layers.Dense(len(np.unique(targets)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cad25d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T14:47:42.585963Z",
     "iopub.status.busy": "2022-05-01T14:47:42.585188Z",
     "iopub.status.idle": "2022-05-01T14:47:42.592368Z",
     "shell.execute_reply": "2022-05-01T14:47:42.591376Z"
    },
    "papermill": {
     "duration": 0.023127,
     "end_time": "2022-05-01T14:47:42.594427",
     "exception": false,
     "start_time": "2022-05-01T14:47:42.571300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_prediction(model, X, y, idx):\n",
    "    genre_dict = {\n",
    "        0 : \"blues\",\n",
    "        1 : \"classical\",\n",
    "        2 : \"country\",\n",
    "        3 : \"disco\",\n",
    "        4 : \"hiphop\",\n",
    "        5 : \"jazz\",\n",
    "        6 : \"metal\",\n",
    "        7 : \"pop\",\n",
    "        8 : \"reggae\",\n",
    "        9 : \"rock\",\n",
    "        }\n",
    "        \n",
    "    predictions = model.predict(X)\n",
    "    genre = np.argmax(predictions[idx])\n",
    "    \n",
    "    print(\"\\n---Now testing the model for one audio file\")\n",
    "    print(\"\\n---The model predicts: {}, and ground truth is: {}.\\n\".format(genre_dict[genre], genre_dict[y[idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a36a2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T14:47:42.622472Z",
     "iopub.status.busy": "2022-05-01T14:47:42.622225Z",
     "iopub.status.idle": "2022-05-01T14:47:42.629713Z",
     "shell.execute_reply": "2022-05-01T14:47:42.628704Z"
    },
    "papermill": {
     "duration": 0.024475,
     "end_time": "2022-05-01T14:47:42.631977",
     "exception": false,
     "start_time": "2022-05-01T14:47:42.607502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function that shows the model's accuracy in a GRAPH.\n",
    "def plot_performance(hist):\n",
    "    \n",
    "    acc = hist.history['acc']\n",
    "    val_acc = hist.history['val_acc']\n",
    "    loss = hist.history['loss']\n",
    "    val_loss = hist.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0115ac16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T14:47:42.659152Z",
     "iopub.status.busy": "2022-05-01T14:47:42.658894Z",
     "iopub.status.idle": "2022-05-01T14:53:06.336374Z",
     "shell.execute_reply": "2022-05-01T14:53:06.335236Z"
    },
    "papermill": {
     "duration": 323.695032,
     "end_time": "2022-05-01T14:53:06.339942",
     "exception": false,
     "start_time": "2022-05-01T14:47:42.644910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # preprocess the data.    \n",
    "    preprocess_data(source_path=SOURCE_PATH, json_path=JSON_PATH)\n",
    "    \n",
    "    # load the data.\n",
    "    inputs, targets = load_data(json_path=JSON_PATH)\n",
    "    \n",
    "    # split the data into training, validation and test sets\n",
    "    # data preparation simple as that.\n",
    "    xtrain, xval, xtest, ytrain, yval, ytest = prepare_datasets(inputs, targets, 0.2)\n",
    "\n",
    "    # design the model.\n",
    "    input_shape = (xtrain.shape[1], xtrain.shape[2], 1)\n",
    "    model = design_model(input_shape)\n",
    "\n",
    "    # Selection of the optimizer, loss type and metrics for performance evaluation.\n",
    "    # still don't really know what it's doing.\n",
    "    model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics = ['acc'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # Training the model. Play Rocky Music.\n",
    "    history = model.fit(xtrain, ytrain,\n",
    "                        validation_data=(xval, yval),\n",
    "                        epochs=30,\n",
    "                        batch_size=32)\n",
    "\n",
    "    # we gonna see if the performance is good.\n",
    "    plot_performance(history)\n",
    "\n",
    "    # Testing the model on never seen before data.\n",
    "    make_prediction(model, xtest, ytest, 24)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 344.740995,
   "end_time": "2022-05-01T14:53:10.469813",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-01T14:47:25.728818",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
